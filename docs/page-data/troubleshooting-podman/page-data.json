{
    "componentChunkName": "component---src-pages-troubleshooting-podman-mdx",
    "path": "/troubleshooting-podman/",
    "result": {"pageContext":{"frontmatter":{"title":"Troubleshooting Workflow Process Service Trial on Podman"},"relativePagePath":"/troubleshooting-podman.mdx","titleType":"page","MdxNode":{"id":"7efb0154-85d3-537d-8ce9-e80e917af909","children":[],"parent":"9fe5fef4-1682-51b0-9d02-db59429223d6","internal":{"content":"---\ntitle: Troubleshooting Workflow Process Service Trial on Podman\n---\n\n## Table of contents\n\n- [Enabling tracing](#enabling-tracing)\n- [Ports are not available](#ports-are-not-available)\n- [Container exits with code 137 or OutOfMemoryError](#container-exits-with-code-137-or-outofmemoryerror)\n- [Can’t access Workplace or Business Automation Studio using Chrome on Mac](#can't-access-workplace-or-business-automation-studio-using-chrome-on-mac)\n- [Error loading cache](#error-loading-cache)\n- [Unable to retrieve authentication token](#unable-to-retrieve-authentication-token)\n- [Opensearch container invalid](#opensearch-container-invalid)\n- [Opensearch endpoint failure](#opensearch-endpoint-failure)\n- [Java Virtual Machine (JVM) crashes with a segmentation error](#java-virtual-machine-(jvm)-crashes-with-a-segmentation-error)\n\n## Enabling tracing\n\nTo enable tracing, update the trace settings in `<local workspace>/config/liberty-custom.xml` after the server starts.  You don't need to restart the server. Changes will take effect after approximately one minute.\n\n## Ports are not available\n\nYou might get the following error message when starting the `pc` container:\n\n```\nERROR: for pc  Cannot start service pc: Ports are not available: listen tcp 0.0.0.0:9443: bind: Only one usage of each socket address (protocol/network address/port) is normally permitted.\n```\n\nThis message means that the host port is already in use. Edit the `docker-compose.yml` file and choose another host port. For example, set the host port to `7443` as seen in the following:\n\n```\n[...]\n  pc:\n    [...]    \n    ports:\n      - \"7443:9443\"\n    [...] \n    environment:\n    [...] \n      - EXTERNAL_HTTPS_PORT=7443\n[...]\n```\n\n After you make the update, use `podman-compose down` to stop and delete the environment and then use  `podman-compose up` to start the environment again.\n\n## Container exits with code 137 or OutOfMemoryError\n\nYou might get an OutOfMemoryError (OOM error) during server startup or you might get the following message when enabling Process Federation Server:\n\n```\nexited with code 137\n```\n\nThis OOM error and the message indicates that a container suddenly exited, probably because the Podman engine didn't have the available resources to run the workload. If the only running Podman containers on your Podman engine are the ones running the Workflow Process Service Trial image and the one running Elasticsearch, you must ensure that you have at least:\n- CPUs: 2\n- Memory: 4.00 GB\n- Swap: 1GB\n\nTo change the settings for your Podman machine, see [Podman machine set](https://docs.podman.io/en/latest/markdown/podman-machine-set.1.html).\n\n\n## Can't access Workplace or Business Automation Studio using Chrome on Mac\n\nIf you can't access Workplace or Business Automation Studio from the Chrome browser on Mac, try another browser. Alternatively, follow these steps:\n\n1. Click the lock icon to the left of the URL.\n2. In the pop-up window, click **Certificate is not valid**.\n3. The next pop-up window shows information about the certificate. Drag the large certificate icon to a Finder window. A `cer` file is created in the location you drag it to.\n4. Open the Keychain Access app on your computer.\n5. Go to the **Certificates** tab and drag your `cer` file onto the Keychain Access app.\n6. Double-click your Workflow Process Service certificate and expand the **Trust** section. Under the **When using this certificate** section, set the value to **Always Trust**.\nClose the dialog box and use your Mac password to save your settings.\n\n## Error loading cache\n\nIf you get the following error message when starting the `pc` container:\n\n```\nWARN[0046] Error validating CNI config file /etc/cni/net.d/root_default.conflist: [plugin bridge does not support config version \"1.0.0\" plugin portmap does not support config version \"1.0.0\" plugin firewall does not support config version \"1.0.0\" plugin tuning does not support config version \"1.0.0\"] \n```\n\nIt might be because the Container Network Interface (CNI) plugins installed on your system are not compatible with the `1.0.0` version configuration in the `/etc/cni/net.d/root_default.conflist` file. To fix this problem, open the `/etc/cni/net.d/root_default.conflist` file and change the configuration from `\"cniVersion\": \"1.0.0\"` to `\"cniVersion\": \"0.4.0\"`.\n\n## Unable to retrieve authentication token\n\nIf you get the following error:\n\n```\nError response from daemon: {\"progressDetail\":{},\"errorDetail\":{\"message\":\"initializing source docker://docker-na-public.artifactory.swg-devops.com/hyc-baw-team-docker-local/bas/workflow-ps-trial:23.0.2-latest-amd64: unable to retrieve auth token: invalid username/password: unknown: Authentication is required\"},\"error\":\"initializing source docker://docker-na-public.artifactory.swg-devops.com/hyc-baw-team-docker-local/bas/workflow-ps-trial:23.0.2-latest-amd64: unable to retrieve auth token: invalid username/password: unknown: Authentication is required\"}\nError: executing C:\\Users\\Administrator\\AppData\\Local\\Microsoft\\WindowsApps\\docker-compose.exe up: exit status 18\n```\n\nIt might be because the `podman compose up` command calls `docker-compose.exe` on Windows, so the Podman login will not work. To fix this problem, run the Podman login command manually. For example:\n\n```bash\npodman login -u <username> -p <password> <registry_url>\n```\n\nAfter you run the command, the credentials will be stored in the configuration file `$HOME/.config/containers/auth.json`. For Docker, the credentials are stored in `$HOME/.docker/config.json` by default. Copy the contents from `$HOME/.config/containers/auth.json` to `$HOME/.docker/config.json`. After this is complete, `docker-compose` will use the correct credentials when pulling the image.\n\n## Opensearch container invalid\n\nIf you get the following error:\n\n```\nError: \"opensearch\" is not a valid container, cannot be used as a dependency: no container with name or ID \"opensearch\" found: no such container\nexit code: 125\n```\n\nEdit the `docker-compose.yml` file and change the Opensearch image configuration to the following:\n\n```bash\nopensearch:\n  image: docker.io/opensearchproject/opensearch:2.7.0\n```\n\n## Opensearch endpoint failure\n\nIf you get the following error:  \n\n\n  ```\n  Failure on endpoint http://opensearch:9200: opensearch. Will not retry before at least 5 seconds\n  ```\n\nRun the following command to check your DNS configuration:  \n\n\n  ```bash\n  podman network ls\n\n  podman network inspect [network_name]\n  ```\n\nIf the output of the command contains `\"dns_enabled\": false`, you need to enable DNS by completing the following steps:\n\n1. Get the IP address of the Opensearch container:\n  ```bash\n  podman inspect opensearch|grep IPAddress\n  ```  \n\n2. Stop the `pc` container by running the following command:  \n  ```bash\n  podman stop pc\n  ```  \n\n3. Open the `docker-compose.yml` file and replace `opensearch` in the line `- PFS_REMOTEELASTICSEARCH_ENDPOINTS=http://opensearch:9200` with the IP address of the Opensearch container.\n\n4. Restart the environment by running the following command:\n  ```bash\n  podman-compose up\n  ```  \n\n## Java Virtual Machine (JVM) crashes with a segmentation error\n\n**Note:** This problem was fixed in 21.0.2 IF002.\n\nThe embedded Java Runtime Environment (JRE) from the Workflow Process Service image might cause Java Virtual Machine (JVM) to crash with a segmentation error, usually after tracing is enabled. When JVM crashes, you see the following segmentation error message in the system error stream:\n\n```\nType=Segmentation error vmState=0x00000000\nJ9Generic_Signal_Number=00000018 Signal_Number=0000000b Error_Value=00000000 Signal_Code=00000080\nHandler1=00007FF6E4FD8470 Handler2=00007FF6E48AD1F0 InaccessibleAddress=0000000000000000\nRDI=00007FF6441C5070 RSI=0000000000000000 RAX=D704122B2A002CB5 RBX=000000000109FF00\nRCX=00000000426F8790 RDX=0000000000000000 R8=0000000000000000 R9=0000000000000000\nR10=FFFFFFFFFFFFFFFF R11=0000000000000000 R12=00007FF6441C5070 R13=00007FF6E52D1800\nR14=D70492216E1C7D3D R15=00007FF65FFFC9D0\nRIP=00007FF6E5083D53 GS=0000 FS=0000 RSP=00007FF65FFFC600\nEFlags=0000000000010202 CS=0033 RBP=00000000000001B8 ERR=0000000000000000\nTRAPNO=000000000000000D OLDMASK=0000000000000000 CR2=0000000000000000\n\n```\n\nTo minimize the chance of a JVM crash, add the JVM parameter `-Xshareclasses:none` when you start the container to disable the shared classes cache. Edit the `docker-compose.yml` file to add `JVM_ARGS='-Xshareclasses:none'` under the environment section. For example:\n\n```\nenvironment:\n      - LICENSE=accept\n      - EXTERNAL_HOSTNAME=localhost\n      - EXTERNAL_HTTPS_PORT=9443\n      # PFS properties\n      - PFS_ENABLE=false\n      - JVM_ARGS='-Xshareclasses:none'\n```\n\n","type":"Mdx","contentDigest":"b9c21c2cc9c26e9f57e6024b146c96b2","owner":"gatsby-plugin-mdx","counter":3831},"frontmatter":{"title":"Troubleshooting Workflow Process Service Trial on Podman"},"exports":{},"rawBody":"---\ntitle: Troubleshooting Workflow Process Service Trial on Podman\n---\n\n## Table of contents\n\n- [Enabling tracing](#enabling-tracing)\n- [Ports are not available](#ports-are-not-available)\n- [Container exits with code 137 or OutOfMemoryError](#container-exits-with-code-137-or-outofmemoryerror)\n- [Can’t access Workplace or Business Automation Studio using Chrome on Mac](#can't-access-workplace-or-business-automation-studio-using-chrome-on-mac)\n- [Error loading cache](#error-loading-cache)\n- [Unable to retrieve authentication token](#unable-to-retrieve-authentication-token)\n- [Opensearch container invalid](#opensearch-container-invalid)\n- [Opensearch endpoint failure](#opensearch-endpoint-failure)\n- [Java Virtual Machine (JVM) crashes with a segmentation error](#java-virtual-machine-(jvm)-crashes-with-a-segmentation-error)\n\n## Enabling tracing\n\nTo enable tracing, update the trace settings in `<local workspace>/config/liberty-custom.xml` after the server starts.  You don't need to restart the server. Changes will take effect after approximately one minute.\n\n## Ports are not available\n\nYou might get the following error message when starting the `pc` container:\n\n```\nERROR: for pc  Cannot start service pc: Ports are not available: listen tcp 0.0.0.0:9443: bind: Only one usage of each socket address (protocol/network address/port) is normally permitted.\n```\n\nThis message means that the host port is already in use. Edit the `docker-compose.yml` file and choose another host port. For example, set the host port to `7443` as seen in the following:\n\n```\n[...]\n  pc:\n    [...]    \n    ports:\n      - \"7443:9443\"\n    [...] \n    environment:\n    [...] \n      - EXTERNAL_HTTPS_PORT=7443\n[...]\n```\n\n After you make the update, use `podman-compose down` to stop and delete the environment and then use  `podman-compose up` to start the environment again.\n\n## Container exits with code 137 or OutOfMemoryError\n\nYou might get an OutOfMemoryError (OOM error) during server startup or you might get the following message when enabling Process Federation Server:\n\n```\nexited with code 137\n```\n\nThis OOM error and the message indicates that a container suddenly exited, probably because the Podman engine didn't have the available resources to run the workload. If the only running Podman containers on your Podman engine are the ones running the Workflow Process Service Trial image and the one running Elasticsearch, you must ensure that you have at least:\n- CPUs: 2\n- Memory: 4.00 GB\n- Swap: 1GB\n\nTo change the settings for your Podman machine, see [Podman machine set](https://docs.podman.io/en/latest/markdown/podman-machine-set.1.html).\n\n\n## Can't access Workplace or Business Automation Studio using Chrome on Mac\n\nIf you can't access Workplace or Business Automation Studio from the Chrome browser on Mac, try another browser. Alternatively, follow these steps:\n\n1. Click the lock icon to the left of the URL.\n2. In the pop-up window, click **Certificate is not valid**.\n3. The next pop-up window shows information about the certificate. Drag the large certificate icon to a Finder window. A `cer` file is created in the location you drag it to.\n4. Open the Keychain Access app on your computer.\n5. Go to the **Certificates** tab and drag your `cer` file onto the Keychain Access app.\n6. Double-click your Workflow Process Service certificate and expand the **Trust** section. Under the **When using this certificate** section, set the value to **Always Trust**.\nClose the dialog box and use your Mac password to save your settings.\n\n## Error loading cache\n\nIf you get the following error message when starting the `pc` container:\n\n```\nWARN[0046] Error validating CNI config file /etc/cni/net.d/root_default.conflist: [plugin bridge does not support config version \"1.0.0\" plugin portmap does not support config version \"1.0.0\" plugin firewall does not support config version \"1.0.0\" plugin tuning does not support config version \"1.0.0\"] \n```\n\nIt might be because the Container Network Interface (CNI) plugins installed on your system are not compatible with the `1.0.0` version configuration in the `/etc/cni/net.d/root_default.conflist` file. To fix this problem, open the `/etc/cni/net.d/root_default.conflist` file and change the configuration from `\"cniVersion\": \"1.0.0\"` to `\"cniVersion\": \"0.4.0\"`.\n\n## Unable to retrieve authentication token\n\nIf you get the following error:\n\n```\nError response from daemon: {\"progressDetail\":{},\"errorDetail\":{\"message\":\"initializing source docker://docker-na-public.artifactory.swg-devops.com/hyc-baw-team-docker-local/bas/workflow-ps-trial:23.0.2-latest-amd64: unable to retrieve auth token: invalid username/password: unknown: Authentication is required\"},\"error\":\"initializing source docker://docker-na-public.artifactory.swg-devops.com/hyc-baw-team-docker-local/bas/workflow-ps-trial:23.0.2-latest-amd64: unable to retrieve auth token: invalid username/password: unknown: Authentication is required\"}\nError: executing C:\\Users\\Administrator\\AppData\\Local\\Microsoft\\WindowsApps\\docker-compose.exe up: exit status 18\n```\n\nIt might be because the `podman compose up` command calls `docker-compose.exe` on Windows, so the Podman login will not work. To fix this problem, run the Podman login command manually. For example:\n\n```bash\npodman login -u <username> -p <password> <registry_url>\n```\n\nAfter you run the command, the credentials will be stored in the configuration file `$HOME/.config/containers/auth.json`. For Docker, the credentials are stored in `$HOME/.docker/config.json` by default. Copy the contents from `$HOME/.config/containers/auth.json` to `$HOME/.docker/config.json`. After this is complete, `docker-compose` will use the correct credentials when pulling the image.\n\n## Opensearch container invalid\n\nIf you get the following error:\n\n```\nError: \"opensearch\" is not a valid container, cannot be used as a dependency: no container with name or ID \"opensearch\" found: no such container\nexit code: 125\n```\n\nEdit the `docker-compose.yml` file and change the Opensearch image configuration to the following:\n\n```bash\nopensearch:\n  image: docker.io/opensearchproject/opensearch:2.7.0\n```\n\n## Opensearch endpoint failure\n\nIf you get the following error:  \n\n\n  ```\n  Failure on endpoint http://opensearch:9200: opensearch. Will not retry before at least 5 seconds\n  ```\n\nRun the following command to check your DNS configuration:  \n\n\n  ```bash\n  podman network ls\n\n  podman network inspect [network_name]\n  ```\n\nIf the output of the command contains `\"dns_enabled\": false`, you need to enable DNS by completing the following steps:\n\n1. Get the IP address of the Opensearch container:\n  ```bash\n  podman inspect opensearch|grep IPAddress\n  ```  \n\n2. Stop the `pc` container by running the following command:  \n  ```bash\n  podman stop pc\n  ```  \n\n3. Open the `docker-compose.yml` file and replace `opensearch` in the line `- PFS_REMOTEELASTICSEARCH_ENDPOINTS=http://opensearch:9200` with the IP address of the Opensearch container.\n\n4. Restart the environment by running the following command:\n  ```bash\n  podman-compose up\n  ```  \n\n## Java Virtual Machine (JVM) crashes with a segmentation error\n\n**Note:** This problem was fixed in 21.0.2 IF002.\n\nThe embedded Java Runtime Environment (JRE) from the Workflow Process Service image might cause Java Virtual Machine (JVM) to crash with a segmentation error, usually after tracing is enabled. When JVM crashes, you see the following segmentation error message in the system error stream:\n\n```\nType=Segmentation error vmState=0x00000000\nJ9Generic_Signal_Number=00000018 Signal_Number=0000000b Error_Value=00000000 Signal_Code=00000080\nHandler1=00007FF6E4FD8470 Handler2=00007FF6E48AD1F0 InaccessibleAddress=0000000000000000\nRDI=00007FF6441C5070 RSI=0000000000000000 RAX=D704122B2A002CB5 RBX=000000000109FF00\nRCX=00000000426F8790 RDX=0000000000000000 R8=0000000000000000 R9=0000000000000000\nR10=FFFFFFFFFFFFFFFF R11=0000000000000000 R12=00007FF6441C5070 R13=00007FF6E52D1800\nR14=D70492216E1C7D3D R15=00007FF65FFFC9D0\nRIP=00007FF6E5083D53 GS=0000 FS=0000 RSP=00007FF65FFFC600\nEFlags=0000000000010202 CS=0033 RBP=00000000000001B8 ERR=0000000000000000\nTRAPNO=000000000000000D OLDMASK=0000000000000000 CR2=0000000000000000\n\n```\n\nTo minimize the chance of a JVM crash, add the JVM parameter `-Xshareclasses:none` when you start the container to disable the shared classes cache. Edit the `docker-compose.yml` file to add `JVM_ARGS='-Xshareclasses:none'` under the environment section. For example:\n\n```\nenvironment:\n      - LICENSE=accept\n      - EXTERNAL_HOSTNAME=localhost\n      - EXTERNAL_HTTPS_PORT=9443\n      # PFS properties\n      - PFS_ENABLE=false\n      - JVM_ARGS='-Xshareclasses:none'\n```\n\n","fileAbsolutePath":"/Users/aliceip/Documents/GitHub/workflow-process-service-trial/github-pages/src/pages/troubleshooting-podman.mdx"}}},
    "staticQueryHashes": ["1364590287","137577622","2102389209","2456312558","2746626797","3018647132","3037994772","768070550"]}